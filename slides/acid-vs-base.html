<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="author" content="Ondra Chaloupka / ochaloup@redhat.com"><title>ACID vs. BASE</title><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui" name="viewport"><link href="reveal.js/css/reveal.css" rel="stylesheet"><link rel="stylesheet" href="reveal.js/css/theme/redhat.css" id="theme"><link href="reveal.js/lib/css/zenburn.css" rel="stylesheet"><script>document.write( '<link rel="stylesheet" href="reveal.js/css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );</script></head><body><div class="reveal"><div class="slides"><section class="title"><h1>ACID vs. BASE</h1><div class="preamble"><aside class="notes"><div class="paragraph"><p><strong>Why this presentation?</strong></p></div>
<div class="paragraph"><p>Distributed systems changed the way how we process data and way how we can think
about transactions. This could give you some summary about the topic.</p></div>
<div class="paragraph"><p><strong>What you will get in this 30+ minutes presentation?</strong></p></div>
<div class="paragraph"><p>Get to know nowadays transaction buzzwords
and get some knowledge what you can use when need to search the Internet :)</p></div>
<div class="paragraph"><p><strong>Disclaimer:</strong> the presentation could contain some simplifications,
  for more details, please, check the topic on your own</p></div>
<div class="paragraph"><p>There are quotes coming from different places on the Internet in the presentation.
All links are mentioned.</p></div></aside></div><p class="author"><small>Ondra Chaloupka / ochaloup@redhat.com</small></p></section>
<section id="_why_transactions"><h2>Why transactions?</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/entertain/wtf2.jpg" alt="wtf2"></span></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>Transactions providing programming model which ease tasks of data manipulation.</p></li><li><p>Transactions provides guarantees which you can build upon (anybody would be
happy having assurance that a data change doesn&#8217;t break data integrity)</p></li></ul></div></aside></section>
<section id="_acid"><h2>ACID</h2><div class="ulist"><ul><li><p><strong>A</strong> for atomicity</p></li><li><p><strong>C</strong> for consistency</p></li><li><p><strong>I</strong> for isolation</p></li><li><p><strong>D</strong> for durability</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Transactions are usually connected with acronym ACID which defines set of properties
of a (database) transaction.</p></div>
<div class="dlist"><dl><dt class="hdlist1"><strong>Atomicity</strong></dt><dd><p>"all or nothing", all operations in a transaction succeed or every operation is rolled back</p></dd><dt class="hdlist1"><strong>Consistency</strong></dt><dd><p>on the completion of a transaction, the database is structurally sound
that covers e.g. preserve foreign keys, uniqueness defined by schema etc.</p></dd><dt class="hdlist1"><strong>Isolation</strong></dt><dd><p>transactions do not contend with one another. Contentious access to data is moderated by the database
so that transactions appear to run sequentially.</p></dd><dt class="hdlist1"><strong>Durability</strong></dt><dd><p>the results of applying a transaction are permanent, even in the presence of failures</p></dd></dl></div>
<div class="paragraph"><p>The ACID acronym came from research of <code>IBM System R</code> from year 1975. Acronym itself
mixes different standpoints about a system (more mnemonic than precise, Brewer 2012)
Following description came from Martin Kleppmann&#8217;s presentation linked below.</p></div>
<div class="paragraph"><p>ACID was coined in 1983, based on work from 1981 (<a href="https://en.wikipedia.org/wiki/ACID" class="bare">https://en.wikipedia.org/wiki/ACID</a>).
The acronym was created based on the implementation of databases at that time.</p></div>
<div class="ulist"><ul><li><p><strong>Durability</strong> means the time when disk does <code>fsync</code> (leave some deeper technical details
about disk writes aside). For transaction it means that data are written to some log
and when system crashes it will be available when started again (we can re-read
the log and restore data).</p></li><li><p><strong>Atomicity</strong> defines possibility to abort transaction and changes done by transaction
in the system will be reverted to state before the transaction starts.
Martin talks that it should be nicer to says <code>abortability</code>.<br>
<em>Atomicity</em> is about handling failures when does depend when they come from (system crash,
network failures, some constraint was broken&#8230;&#8203;).<br>
<em>Atomicity</em> is <strong>not</strong> about concurrency. Rather <em>Isolation</em> is about concurrency -
meaning parallel transaction works on the same piece of data.</p></li><li><p><strong>Consistency</strong> is to having the system in consistent state (moving from one to other one).
<em>Consistency</em> is a point of view of an application in fact.<br>
<em>Consistency</em> means fulfilling   invariants which could be defined in DB model
but they could be outside of it too.</p></li><li><p><strong>Isolation</strong> is about concurrency. In perspective of this presentation the <em>Isolation</em>
property is the most interesting. When talking about <em>ACID</em> isolation it&#8217;s meant
<em>Serializability</em> to be obtained.</p></li><li><p><a href="https://en.wikipedia.org/wiki/ACID" class="bare">https://en.wikipedia.org/wiki/ACID</a></p></li><li><p><a href="https://martin.kleppmann.com/2015/11/04/transactions-at-code-mesh.html" class="bare">https://martin.kleppmann.com/2015/11/04/transactions-at-code-mesh.html</a></p></li></ul></div></aside></section>
<section id="_isolation"><h2>Isolation</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/isolation-levels-base.png" alt="isolation levels base"></span></p></div>
<aside class="notes"><div class="paragraph"><p>Isolation talks about behavior when running two (multiple) concurrent transaction.<br>
We know classic isolation levels defined by ANSI/ISO SQL standard. Those are based
on notion of locking (lock-based concurrency control). I&#8217;m mentioning locks in the list
belows but it&#8217;s just naive way of thinking about locking. Real DBs has much more sophisticated
ways to lock thinks (e.g. check M$ articles about locks)</p></div>
<div class="dlist"><dl><dt class="hdlist1"><strong>None</strong></dt><dd><div class="ulist"><ul><li><p>locks: no</p></li><li><p>struggles <em>dirty writes (P0)</em></p></li><li><p>you can read corrupted data that as other transaction hasn&#8217;t ended with an operation yet</p></li><li><p>means that your not committed work could be rewritten by other "transaction" meanwhile.</p></li><li><p>here is interesting point about <em>lost update (P4)</em> phenomena<br>
you can read at some places that the minimum transaction isolation level to avoid it is
<em>read uncommitted</em>. Which is partly true. The issue (as I understand it) is that the term
<em>lost update</em> is not precisely specified. For <em>read uncommitted</em> solves this phenomena it has to
mean that other transaction can interleave writing a data which can lead to corruption of data
(no lock acquired, two transaction writing to the same place at the same time)</p><div class="ulist"><ul><li><p>but <em>lost update (P4)</em> is specified rather differently (more broader), fist or second</p></li><li><p>data that has been updated by one transaction is overwritten by another transaction,
before the first transaction is either committed or rolled back</p></li><li><p>one transaction reads data into its local memory, and then another transaction changes
this data and commits its change. After this, the first transaction updates the same data based
on what it read into memory before another transaction was executed. In this case,
the update performed by the another transaction can be considered a lost update.</p></li><li><p>the later trouble connects to contention errors too (deadlocks) and it&#8217;s a thing which Hibernate (ORM)
tries to solve (entities are loaded to cache), as solution you can then using optimistic locking
(version added to data and exception thrown when concurrent change happens) or pessimistic
(<code>select &#8230;&#8203; for update</code> is used which causes acquiring exclusive write lock on  accessed rows)</p></li></ul></div></li></ul></div></dd><dt class="hdlist1"><strong>Read uncommitted</strong></dt><dd><div class="ulist"><ul><li><p>struggles <em>dirty reads (P1)</em> phenomena</p></li><li><p>locks: acquires write lock only for the operation and releases immediately</p></li><li><p>means you can read uncommitted changes of a different transaction. But you can&#8217;t write
to data which was changed by some concurrent transaction.</p></li></ul></div></dd><dt class="hdlist1"><strong>Read committed</strong></dt><dd><div class="ulist"><ul><li><p>struggles <em>(fuzzy) non-repeatable reads (P2)</em> phenomena</p></li><li><p>locks: acquires write lock to the end of transaction, read lock is released immediately after select ends</p></li><li><p>means that other transaction reading the same data several times can see different values
during it&#8217;s executions. Transaction one starts and reads X being 1. Meanwhile transaction
two stats, writes X to be 2 and commits. Transaction one reads X again and it can see it being 2.</p></li><li><p>generally prevents users from reading uncommitted or non-final writes but allows a number of bad
things to happen, like lost updates during concurrent read-modify-write operations</p></li></ul></div></dd><dt class="hdlist1"><strong>Repeatable reads</strong></dt><dd><div class="ulist"><ul><li><p>struggles <em>phantom reads (P3)</em> phenomena</p></li><li><p>locks: acquires write and read lock for records working with till the end of transaction</p></li><li><p>means that reading a set of data over a table could change during life time. Transaction one starts
and selects <code>SELECT * from MYTABLE</code>, Transaction two starts, insert a row to the table <code>MYTABLE</code>
and ends. Transaction one selects <code>MYTABLE</code> again and it can see different number of results now.</p></li></ul></div></dd><dt class="hdlist1"><strong>Serializable</strong></dt><dd><div class="ulist"><ul><li><p>'complete' isolation of transaction</p></li><li><p>locks read, write and range lock when select is used are acquired till the end of transaction</p></li></ul></div></dd></dl></div>
<div class="paragraph"><p>Now we can see there is not only those isolation levels but the diagram shows <strong>Snapshot isolation (MVCC)</strong>.
That&#8217;s a different approach of solving the concurrency control issue. We do not use locks but a snapshot
of data is taken at time when transaction starts. Transaction then works with the data which was available
at point of transaction started. Still for being sure to not get issues on writing data we need to
acquires write locks (but we don&#8217;t need read locks). Acquiring locks is a pesimistic way of solving the issue,
the optimistic one is to record writing and in case of conflicting abort the transaction and retry it again.
In systems with no much contentions it works fine. See more about <strong>Serializable Snaphost Isolation</strong> e.g.
at PostgreSQL web.</p></div>
<div class="paragraph"><p>Let&#8217;s shortly mention other two more concurrency control issues which connect to snapshot isolation.
The schema on this slide is not exact as lock based repeatable read avoids <em>non-repeatable reads</em>
and <em>read skew</em> (which could be taken as special case of <em>non-repeatable reads</em>) but it avoids
<em>write skew</em> too which is not avoided by <em>snapshot isolation</em> (when not talking about <em>SSI</em>).</p></div>
<div class="dlist"><dl><dt class="hdlist1"><strong>Read Skew</strong> (A5A)</dt><dd><div class="ulist"><ul><li><p>not avoided when using <em>read committed</em> isolation level,
avoided when <em>snapshot isolation</em> is used and when <em>repeatable read</em> is used</p></li><li><p>variation on <em>non-repeatable reads</em>. When transaction 1 selects record a,
transaction 2 sneaks and updates the record 1 and record 2, transaction 1 resumes
and selects record 2. Transaction 1 does not see the picture of the world as it was
when it starts (when it read record 1).</p></li></ul></div></dd><dt class="hdlist1"><strong>Write Skew</strong> (A5B)</dt><dd><div class="ulist"><ul><li><p>avoided when using <em>repeatable read</em> isolation level (based on locks),
not avoided when <em>snapshot isolation</em> is used. Occurs when transaction are not <em>serializable</em>.</p></li><li><p>it defines situation of some constraint being put at application level. For example that at least
one counter in a table has to be non-zero (Martin makes example in his presentation on at least
one physician has be in attendance and all decide that decline his attendance in the same time).
There is important here that two transactions operates on different records thus it does not
influence each other directly on write.<br>
When back to counter we have this DB table:</p></li></ul></div></dd></dl></div>
<table class="tableblock frame-all grid-all" style="width:100%"><colgroup><col style="width:50%"><col style="width:50%"></colgroup><thead><tr><th class="tableblock halign-left valign-top">ID</th><th class="tableblock halign-left valign-top">Counter</th></tr></thead><tbody><tr><td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td><td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td><td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td></tr></tbody></table>
<div class="paragraph"><p>Now transactions runs concurrently</p></div>
<table class="tableblock frame-all grid-all" style="width:100%"><colgroup><col style="width:50%"><col style="width:50%"></colgroup><thead><tr><th class="tableblock halign-left valign-top">Transaction 1</th><th class="tableblock halign-left valign-top">Transaction 2</th></tr></thead><tbody><tr><td class="tableblock halign-left valign-top"><p class="tableblock">BEGIN txn 1</p></td><td class="tableblock halign-left valign-top"><p class="tableblock">BEGIN txn 2</p></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock">SELECT * FROM table</p></td><td class="tableblock halign-left valign-top"><p class="tableblock">SELECT * FROM table</p></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock">check there if there is some other record with counter &gt;= 1</p></td><td class="tableblock halign-left valign-top"><p class="tableblock">check there if there is some other record with counter &gt;= 1</p></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock">set counter of <strong>ID 1</strong> to <strong>0</strong></p></td><td class="tableblock halign-left valign-top"><p class="tableblock">set counter of <strong>ID 2</strong> to <strong>0</strong></p></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock">COMMIT</p></td><td class="tableblock halign-left valign-top"><p class="tableblock">COMMIT</p></td></tr></tbody></table>
<div class="paragraph"><p>At the end both counters (counter of ID = 1 and ID = 2)
are zero which is violation of constraint application has.</p></div>
<div class="ulist"><ul><li><p><a href="https://martin.kleppmann.com/2014/11/25/hermitage-testing-the-i-in-acid.html" class="bare">https://martin.kleppmann.com/2014/11/25/hermitage-testing-the-i-in-acid.html</a></p></li><li><p><a href="http://blog.triona.de/development/database/acid-and-isolation-level-overview.html" class="bare">http://blog.triona.de/development/database/acid-and-isolation-level-overview.html</a></p></li><li><p><a href="http://ithare.com/databases-101-acid-mvcc-vs-locks-transaction-isolation-levels-and-concurrency" class="bare">http://ithare.com/databases-101-acid-mvcc-vs-locks-transaction-isolation-levels-and-concurrency</a></p></li><li><p><a href="https://technet.microsoft.com/en-us/library/jj856598" class="bare">https://technet.microsoft.com/en-us/library/jj856598</a></p></li><li><p><a href="http://technet.microsoft.com/en-us/library/cc546518.aspx" class="bare">http://technet.microsoft.com/en-us/library/cc546518.aspx</a></p></li><li><p><a href="https://www.simple-talk.com/sql/t-sql-programming/developing-modifications-that-survive-concurrency" class="bare">https://www.simple-talk.com/sql/t-sql-programming/developing-modifications-that-survive-concurrency</a></p></li><li><p><a href="https://wiki.postgresql.org/wiki/SSI" class="bare">https://wiki.postgresql.org/wiki/SSI</a></p></li><li><p><a href="https://vladmihalcea.com/2015/10/20/a-beginners-guide-to-read-and-write-skew-phenomena" class="bare">https://vladmihalcea.com/2015/10/20/a-beginners-guide-to-read-and-write-skew-phenomena</a></p></li><li><p><a href="https://vladmihalcea.com/2017/01/31/a-beginners-guide-to-the-phantom-read-anomaly-and-how-it-differs-between-2pl-and-mvcc/" class="bare">https://vladmihalcea.com/2017/01/31/a-beginners-guide-to-the-phantom-read-anomaly-and-how-it-differs-between-2pl-and-mvcc/</a></p></li><li><p><a href="http://www.bailis.org/blog/understanding-weak-isolation-is-a-serious-cap" class="bare">http://www.bailis.org/blog/understanding-weak-isolation-is-a-serious-cap</a></p></li></ul></div></aside></section>
<section id="_write_skew"><h2>Write skew</h2><div class="listingblock"><div class="content"><pre class="highlight"><code>t1 --- read x &lt;- 2 --- write y -&gt; 6 --- commit

t2 --- read y &lt;- 3 --- write x -&gt; 7 --- commit</code></pre></div></div>
<div class="ulist"><ul><li><p>at start <code>x = 2</code>, <code>y = 3</code></p></li><li><p>constraint defined: <code>a + b =&lt; 10</code></p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>perfect summary at: <a href="https://blog.acolyer.org/2016/02/24/a-critique-of-ansi-sql-isolation-levels" class="bare">https://blog.acolyer.org/2016/02/24/a-critique-of-ansi-sql-isolation-levels</a></p></div></aside></section>
<section id="_isolation_in_real_world"><h2>Isolation in real world</h2><div class="ulist"><ul><li><p><a href="https://github.com/ept/hermitage" class="bare">https://github.com/ept/hermitage</a></p></li><li><p><a href="http://www.bailis.org/blog/when-is-acid-acid-rarely" class="bare">http://www.bailis.org/blog/when-is-acid-acid-rarely</a></p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Links contains tables where are depicted default and maximum isolation levels
for particular databases.</p></div></aside></section>
<section id="_isolation_for_distributed_world"><h2>Isolation for distributed world</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/isolation-levels-hat.png" alt="isolation levels hat"></span></p></div>
<aside class="notes"><div class="paragraph"><p>Some more info about distributed DBs and HA in a while but here we can see a picture
of Peter Bailis paper <em>HAT, not CAP: Introducing Highly Available Transactions</em>.</p></div>
<div class="ulist"><ul><li><p>It presents what are isolation levels available for HA (AP from CAP) systems.</p></li><li><p>Those marked as red are not available for CA.</p></li><li><p>Those marked in blue are available for sticky availability.</p></li><li><p>Those which are on the left side of the picture (RU, RC, RR, SI, 1SR) are those
discussed in previous slide. The part on the right side belongs to the distributed
world that we talk about in a while.</p></li></ul></div>
<table class="tableblock frame-all grid-all" style="width:100%"><colgroup><col style="width:50%"><col style="width:50%"></colgroup><tbody><tr><td class="tableblock halign-left valign-top"><p class="tableblock">HA</p></td><td class="tableblock halign-left valign-top"><p class="tableblock">Read Uncommitted (RU), Read Committed (RC),
  Monotonic Atomic View (MAV), Item
  Cut Isolation (I-CI), Predicate Cut Isolation (P-CI),
  Writes Follow Reads (WFR), Monotonic Reads (MR),
  Monotonic Writes (MW)</p></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock">Sticky</p></td><td class="tableblock halign-left valign-top"><p class="tableblock">Read Your Writes (RYW), PRAM, Causal</p></td></tr><tr><td class="tableblock halign-left valign-top"><p class="tableblock">Unavailable</p></td><td class="tableblock halign-left valign-top"><p class="tableblock">Cursor Stability (CS)† , Snapshot Isolation (SI)† ,
  Repeatable Read (RR)†‡ , One-Copy Serializability (1SR)†‡,
  Recency , Safe , Regular , ⊕Linearizability , Strong 1SR†‡</p></td></tr></tbody></table>
<div class="paragraph"><p>I would like quickly touch one topic here which is Serializability vs.
Linearizability. It&#8217;s interesting from point that even serializable isolation level
can&#8217;t be taken as the level of the most guarantees. Still there is a <em>Strict Serializability</em>.</p></div>
<div class="paragraph"><p>To quote Peter Bailis here</p></div>
<div class="ulist"><ul><li><p><strong>Linearizability</strong> is a guarantee about single operations on single objects. It provides a real-time
(i.e., wall-clock) guarantee on the behavior of a set of single operations (often reads and writes)
on a single object (e.g., distributed register or data item).</p><div class="ulist"><ul><li><p><em>Linearizability</em> for read and write operations is synonymous with the term <code>"atomic consistency"`</code>
and is the <code>"C"</code>, or <code>consistency</code>, in Gilbert and Lynch’s proof of the <em>CAP Theorem</em>.</p></li></ul></div></li><li><p><strong>Serializability</strong> is a guarantee about transactions, or groups of one or more operations over one or
more objects. It guarantees that the execution of a set of transactions (usually containing read and
write operations) over multiple items is equivalent to some serial execution (total ordering)
of the transactions.</p><div class="ulist"><ul><li><p><em>Serializability</em> is the traditional <code>"I"`</code>, or <code>isolation</code>, in <em>ACID</em>.</p></li></ul></div></li><li><p><a href="http://www.bailis.org/blog/hat-not-cap-introducing-highly-available-transactions" class="bare">http://www.bailis.org/blog/hat-not-cap-introducing-highly-available-transactions</a></p></li><li><p><a href="http://www.bailis.org/blog/linearizability-versus-serializability" class="bare">http://www.bailis.org/blog/linearizability-versus-serializability</a></p></li><li><p><a href="https://blog.acolyer.org/2016/02/26/distributed-consistency-and-session-anomalies" class="bare">https://blog.acolyer.org/2016/02/26/distributed-consistency-and-session-anomalies</a></p></li><li><p><a href="https://www.youtube.com/watch?v=Ih0Efbx0cE8" class="bare">https://www.youtube.com/watch?v=Ih0Efbx0cE8</a> : Adrian Colyer - Out of the Fire Swamp</p></li></ul></div></aside></section>
<section id="_serializability"><h2>Serializability</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/serialization.png" alt="serialization"></span></p></div>
<aside class="notes"><div class="paragraph"><p>Serialization talks about multiple items groups under one transaction.
Those transaction can be put to arbitrary order but they are executed in serial.</p></div>
<div class="paragraph"><p>Easy to imagine is to run on one node in one thread transaction by transaction.</p></div></aside></section>
<section id="_linearizability"><h2>Linearizability</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/linearizability.png" alt="linearizability"></span></p></div>
<aside class="notes"><div class="paragraph"><p>Linearizability talks operation on single object to be done in the same order
on multiple nodes.</p></div>
<div class="paragraph"><p>In other words it ensures that all operations on single object is executed in the same order
on all nodes.</p></div></aside></section>
<section id="_distributed_strict_serializability"><h2>Distributed (strict) serializability</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/consensus-atomic-ordering-kleppmann.png" alt="consensus atomic ordering kleppmann"></span></p></div>
<div class="paragraph"><p><em>source:</em> <a href="https://www.youtube.com/watch?v=5ZjhNTM8XU8&amp;t=2300">Martin Kleppmann</a></p></div>
<aside class="notes"><div class="paragraph"><p>Here I would like check with you what are things to achieve <strong>serializable transactions</strong>
in distributed environment.
For that we need an <strong>atomic commitment protocol</strong> (all of them protocol or nono of them commit)
and for that work in distributed environment we are in fight with <strong>ordering</strong>.
And total ordering is in fact a problem of <strong>consensus</strong>.</p></div>
<div class="paragraph"><p>Consensus requires quite a lot of coordination.</p></div>
<div class="paragraph"><p>Possible uses of consensus are:</p></div>
<div class="ulist"><ul><li><p>deciding whether or not to commit a transaction to a database</p></li><li><p>synchronising clocks by agreeing on the current time</p></li><li><p>agreeing to move to the next stage of a distributed algorithm (this is the famous replicated state machine approach)</p></li><li><p>electing a leader node to coordinate some higher-level protocol</p></li></ul></div>
<div class="paragraph"><p>Several computers (or nodes) achieve consensus if they all agree on some value. More formally:</p></div>
<div class="olist arabic"><ol class="arabic"><li><p>Agreement: Every correct process must agree on the same value.</p></li><li><p>Integrity: Every correct process decides at most one value, and if it decides some value, then it must have been proposed by some process.</p></li><li><p>Termination: All processes eventually reach a decision.</p></li><li><p>Validity: If all correct processes propose the same value V, then all correct processes decide V.</p></li></ol></div>
<div class="paragraph"><p>Time and consistency</p></div>
<div class="paragraph"><p>When mutable state is distributed over multiple machines each machine can receive update events
at different times and in different orders. If the final state is dependent on the order of updates
then the system must choose a single serialisation of the events, imposing a global total order.
A distributed system is consistent exactly when the outside world can never observe two different serialisations.</p></div>
<div class="paragraph"><p>A step aside: FLP</p></div>
<div class="paragraph"><p>FLP talks on problem of consensus</p></div>
<div class="listingblock"><div class="content"><pre class="highlight"><code>Having all nodes agree on a common value - is unsolvable
in general in asynchronous networks where one node might fail.</code></pre></div></div>
<div class="paragraph"><p>This is only a side node to the fact that scientists considers different models
to describe distributed systems and the '<em>CAP issue</em>'.</p></div>
<div class="ulist"><ul><li><p>FLP permits the possibility of one 'failed' node which is totally partitioned from the network
and does not have to respond to requests.</p></li><li><p>Otherwise, FLP does not allow message loss; the network is only asynchronous but not lossy.</p></li><li><p>FLP deals with consensus, which is a similar but different problem to atomic storage.</p></li><li><p><a href="https://blog.acolyer.org/2015/09/02/the-potential-dangers-of-causal-consistency-and-an-explicit-solution" class="bare">https://blog.acolyer.org/2015/09/02/the-potential-dangers-of-causal-consistency-and-an-explicit-solution</a></p></li><li><p><a href="http://book.mixu.net/distsys/single-page.html" class="bare">http://book.mixu.net/distsys/single-page.html</a></p></li><li><p><a href="https://aphyr.com/posts/322-call-me-maybe-mongodb-stale-reads" class="bare">https://aphyr.com/posts/322-call-me-maybe-mongodb-stale-reads</a></p></li><li><p><a href="http://scattered-thoughts.net/blog/2012/08/16/causal-ordering/" class="bare">http://scattered-thoughts.net/blog/2012/08/16/causal-ordering/</a></p></li></ul></div></aside></section>
<section id="_cap"><h2>CAP</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/cap-consensus.png" alt="cap consensus"></span></p></div>
<aside class="notes"><div class="paragraph"><p>(<em>Coined by <code>Dr. Eric Brewer</code> by talk <code>Towards Robust Distributed Systems</code> in 2000.</em>
<em>Seth Gilbert and Professor Nancy Lynch formalized in 2002.</em>)</p></div>
<div class="paragraph"><p>The CAP Theorem (henceforth 'CAP') says that it is impossible to build an implementation of read-write storage
in an asynchronous network that satisfies all of the three properties. We are constrained only to two of them.</p></div>
<div class="dlist"><dl><dt class="hdlist1"><strong>Availability</strong></dt><dd><p>will a request made to the data store always eventually complete</p></dd><dt class="hdlist1"><strong>Consistency</strong></dt><dd><p>will all executions of reads and writes seen by all nodes be atomic or linearizably consistent</p></dd><dt class="hdlist1"><strong>Partition tolerance</strong></dt><dd><p>the network is allowed to drop any messages.</p></dd></dl></div>
<div class="paragraph"><p>It&#8217;s a popular and fairly useful way to think about tradeoffs in the guarantees that a system design makes.</p></div>
<div class="paragraph"><p>In <em>normal</em> distributed system we can&#8217;t take off <strong>P</strong> - we are limited for <strong>CP</strong> or <strong>AP</strong>.</p></div>
<div class="paragraph"><p>The diagram shows <strong>CA</strong> as <strong>2PC</strong>. It&#8217;s possible in way that we avoid partition to happens
by not using distributed execution, by running on single node.
Then we got to well known XA distributed transactions 2PC aka. ACID.</p></div>
<div class="paragraph"><p>And hey, wait a minute, this talk about <code>read-write storage</code> and not any transaction ;)</p></div>
<div class="paragraph"><p>Let&#8217;s revise the <strong>CAP</strong> acronym once again</p></div>
<div class="dlist"><dl><dt class="hdlist1"><strong>Partition-Tolerant environment</strong></dt><dd><p>ability of the whole system to continue to work (accept requests and process them reliably) even
when any number of messages fail in communications.</p><div class="ulist"><ul><li><p>the basic prove of <strong>CAP theorem</strong> is based on having two nodes split (brain split), each of them
starts to process different requests but they can&#8217;t communicate with each other. The system as whole
is then inconsistent (consistency in CAP way of thinking). Each node responses different value on reading.</p></li><li><p>Consistency has multiple forms - CAP talks about linearizability (strict consistency)</p></li></ul></div></dd><dt class="hdlist1"><strong>Consistency</strong></dt><dd><p>defines a consistency model that system work with. the characteristic is whether every read would return
the latest written information (or error), it&#8217;s a degree of how soon the changes done by your transaction
is visible to other transactions</p><div class="ulist"><ul><li><p>Very often people attempting to introduce eventual consistency into a system run into problems from
the business side. Business users hear "consistency" and they tend to think it means
that the data will be wrong. That the data will be incoherent and contradictory.)</p></li></ul></div></dd><dt class="hdlist1"><strong>Availability</strong></dt><dd><p>excects that every request receives a non-error response</p><div class="ulist"><ul><li><p>Cloud providers have broadened the interpretation of the CAP theorem in the sense that they consider
a system to be unavailable if the response time exceeds the latency limit.</p></li><li><p>CAP talks about total availability</p></li></ul></div></dd></dl></div>
<div class="paragraph"><p>Saying this implies that <code>CA</code> and <code>CP/AP</code> are not about the same face of a distributed system:
* <code>CA</code> is a specification of the operating range: you specify that the system does not work well under partition or,
  more precisely, that partitions are outside the operating range of the system.
* <code>CP</code> or <code>AP</code> describes the behavior: what happens if there is a partition.</p></div>
<div class="ulist"><ul><li><p><a href="https://henryr.github.io/cap-faq" class="bare">https://henryr.github.io/cap-faq</a></p></li><li><p><a href="http://book.mixu.net/distsys/single-page.html" class="bare">http://book.mixu.net/distsys/single-page.html</a></p></li><li><p><a href="https://medium.com/@cinish/database-acid-cap-isolation-levels-371b7e06a112" class="bare">https://medium.com/@cinish/database-acid-cap-isolation-levels-371b7e06a112</a></p></li><li><p><a href="https://msdn.microsoft.com/en-us/library/jj591577.aspx" class="bare">https://msdn.microsoft.com/en-us/library/jj591577.aspx</a></p></li><li><p><a href="http://www.cs.utexas.edu/~dsb/cs386d/Projects14/CAPConsistency.pdf" class="bare">http://www.cs.utexas.edu/~dsb/cs386d/Projects14/CAPConsistency.pdf</a></p></li><li><p><a href="http://www.julianbrowne.com/article/viewer/brewers-cap-theorem" class="bare">http://www.julianbrowne.com/article/viewer/brewers-cap-theorem</a></p></li><li><p><a href="http://blog.thislongrun.com/2015/04/the-unclear-cp-vs-ca-case-in-cap.html" class="bare">http://blog.thislongrun.com/2015/04/the-unclear-cp-vs-ca-case-in-cap.html</a></p></li><li><p><a href="http://www.julianbrowne.com/article/viewer/brewers-cap-theorem" class="bare">http://www.julianbrowne.com/article/viewer/brewers-cap-theorem</a></p></li></ul></div></aside></section>
<section id="_consistency_in_baseball_game"><h2>Consistency in baseball game</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/baseball-consistency-2.png" alt="baseball consistency 2"></span></p></div>
<div class="paragraph"><p><em>source:</em> <a href="https://www.microsoft.com/en-us/research/publication/replicated-data-consistency-explained-through-baseball">Replicated Data Consistency Explained Through Baseball</a></p></div>
<aside class="notes"><div class="paragraph"><p>Consistency model (aka consistency semantics)</p></div>
<div class="ulist"><ul><li><p>Contract between processes and the data store</p><div class="ulist"><ul><li><p>If processes obey certain rules, data store will work correctly</p></li></ul></div></li><li><p>All models attempt to return the results of the last write for a read operation</p><div class="ulist"><ul><li><p>Differ in how “last” write is determined/defined</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>Strict consistency is sometimes referred as strong consistency.</p></div>
<div class="paragraph"><p>Consistency models: Data-centric</p></div>
<div class="ulist"><ul><li><p>Strict consistency</p><div class="ulist"><ul><li><p>reads returns the most recent writes</p></li></ul></div></li><li><p>Linearizability</p><div class="ulist"><ul><li><p>sequential consistent and time ordering</p></li></ul></div></li><li><p>Sequential consistency</p><div class="ulist"><ul><li><p>ops executed in some sequential order</p></li></ul></div></li><li><p>Causal consistency</p><div class="ulist"><ul><li><p>reads are seen in the same order</p></li></ul></div></li><li><p>Eventual consistency</p></li></ul></div>
<div class="paragraph"><p>Consistency models: Client-centric</p></div>
<div class="ulist"><ul><li><p>Monotonic reads</p></li><li><p>Monotonic writes</p></li><li><p>Read your writes</p></li><li><p>Writes follow reads</p></li></ul></div>
<div class="paragraph"><p><em>and some unordered notes&#8230;&#8203;</em></p></div>
<div class="ulist"><ul><li><p>Strong consistency models (capable of maintaining a single copy)</p><div class="ulist"><ul><li><p>Linearizable consistency: Under linearizable consistency, all operations appear to have
executed atomically in an order that is consistent with the global real-time ordering of operations. (Herlihy &amp; Wing, 1991)</p></li><li><p>Sequential consistency: Under sequential consistency, all operations appear to have executed
atomically in some order that is consistent with the order seen at individual nodes and that is equal at all nodes. (Lamport, 1979)</p><div class="ulist"><ul><li><p>Paxos. Paxos is one of the most important algorithms when writing strongly consistent partition tolerant replicated systems.
It is used in many of Google&#8217;s systems, including the Chubby lock manager used by BigTable/Megastore,
the Google File System as well as Spanner.</p></li><li><p>ZAB. ZAB - the Zookeeper Atomic Broadcast</p></li><li><p>Raft - easier Paxos</p></li></ul></div></li></ul></div></li><li><p>Weak consistency models (not strong)</p><div class="ulist"><ul><li><p>Client-centric consistency models: many kinds of consistency models that are client-centric</p></li><li><p>Causal consistency: strongest model available, strongest is global causal+ consistency
– global as in needing to coordinate across datacenters, and the ‘+‘ to indicate that we care about convergence</p></li><li><p>Eventual consistency models</p><div class="ulist"><ul><li><p>Eventual consistency with probabilistic guarantees : Amazon&#8217;s Dynamo
(LinkedIn&#8217;s Voldemort, Facebook&#8217;s Cassandra and Basho&#8217;s Riak based on that)</p></li><li><p>Eventual consistency with strong guarantees : CRDT, CALM</p></li></ul></div></li></ul></div></li></ul></div>
<div class="paragraph"><p>Causal consistency (<a href="https://www.quora.com/Distributed-Systems-What-is-a-causal-consistency" class="bare">https://www.quora.com/Distributed-Systems-What-is-a-causal-consistency</a>)</p></div>
<div class="ulist"><ul><li><p>A system is causally consistent if all agents see (only) causally related events in the same order.
This is weaker than sequential consistency because the later requires all events appear in the same order,
irrespective of causality. My favorite example is from <a href="http://www-bcf.usc.edu/~wyattllo/papers/causal-login13.pdf" class="bare">http://www-bcf.usc.edu/~wyattllo/papers/causal-login13.pdf</a></p></li><li><p>Causal consistency improves user experience because with it actions appear to everyone in the correct order.
A common scenario where causality is important, but often isn’t provided,
is comments on social network posts, which sometimes appear out of order.</p><div class="ulist"><ul><li><p>e.g.
<code>`
[Removes boss from friends list]
[Posts]: “My boss is the worst, I need a new job!”
</code>`
If these two actions occur in the wrong order, then my post will not have been hidden
from my boss as intended. Bad news bears. Good news is that with causal consistency me myself can
see the changes in good order ;-)</p></li></ul></div></li><li><p><a href="http://lass.cs.umass.edu/~shenoy/courses/spring05/lectures/Lec15.pdf" class="bare">http://lass.cs.umass.edu/~shenoy/courses/spring05/lectures/Lec15.pdf</a></p></li><li><p><a href="http://www.bailis.org/blog/understanding-weak-isolation-is-a-serious-problem" class="bare">http://www.bailis.org/blog/understanding-weak-isolation-is-a-serious-problem</a></p></li><li><p><a href="https://www.microsoft.com/en-us/research/publication/replicated-data-consistency-explained-through-baseball" class="bare">https://www.microsoft.com/en-us/research/publication/replicated-data-consistency-explained-through-baseball</a></p></li><li><p><a href="https://www.youtube.com/watch?v=yCcWpzY8dIA" class="bare">https://www.youtube.com/watch?v=yCcWpzY8dIA</a> (GOTO 2016, Conflict Resolution for Eventual Consistency, Martin Kleppmann)</p></li></ul></div></aside></section>
<section id="_cap_strong_cp_strong"><h2>CAP - <strong>CP</strong></h2><div class="paragraph"><p><a href="http://thesecretlivesofdata.com/raft" class="bare">http://thesecretlivesofdata.com/raft</a></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>CP (consistency + partition tolerance). Basically those are <strong>majority quorum protocols</strong>
in which minority partitions are unavailable such as Paxos, ZAB (<strong>ZooKeeper</strong>), Raft.</p></li><li><p>Paxos - Chubby, Doozer</p></li><li><p>Zab - ZooKeeper</p></li><li><p>Raft - Consul, etcd</p></li><li><p>Viestamp replication - ?</p></li></ul></div>
<div class="paragraph"><p>2PC, Paxos, and various approaches to quorum - these protocols provide the application programmer
a façade of global serializability.</p></div>
<div class="paragraph"><p>If you don’t want to lose linearizability, you have to make sure you do
all your reads and writes in one datacenter, which you may call the leader.</p></div>
<div class="paragraph"><p>RAFT</p></div>
<div class="paragraph"><p>Raft is a consensus algorithm for implementing fault tolerant distributed systems
using a replicated state machine approach.</p></div>
<div class="paragraph"><p>Raft is "simplification" of Paxos, mainly for being easier to explain</p></div>
<div class="paragraph"><p>There are two topics to talk about</p></div>
<div class="ulist"><ul><li><p>leader election</p></li><li><p>log replication</p></li><li><p><a href="http://the-paper-trail.org/blog/distributed-systems-theory-for-the-distributed-systems-engineer" class="bare">http://the-paper-trail.org/blog/distributed-systems-theory-for-the-distributed-systems-engineer</a></p></li><li><p><a href="http://thesecretlivesofdata.com/raft" class="bare">http://thesecretlivesofdata.com/raft</a></p></li><li><p><a href="http://the-paper-trail.org/blog/consensus-protocols-paxos" class="bare">http://the-paper-trail.org/blog/consensus-protocols-paxos</a></p></li><li><p><a href="https://loonytek.com/2015/10/18/leader-election-and-log-replication-in-raft-part-1" class="bare">https://loonytek.com/2015/10/18/leader-election-and-log-replication-in-raft-part-1</a></p></li><li><p><a href="http://blog.nahurst.com/visual-guide-to-nosql-systems" class="bare">http://blog.nahurst.com/visual-guide-to-nosql-systems</a></p></li></ul></div></aside></section>
<section id="_cap_strong_ap_strong"><h2>CAP - <strong>AP</strong></h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/ap.png" alt="ap"></span></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>AP (availability + partition tolerance). Basically those are <strong>protocols using conflict resolution</strong>,
such as Dynamo.</p></li></ul></div>
<div class="paragraph"><p>The easiest way how to resolve conflict is to move the responsibility to client.
If there is a conflict DB returns to client both results and it&#8217;s up to client
what it does - uses both, rewrites one as the correct record&#8230;&#8203;
Other used and easy way is having kind of versioning system (kind of git in database).
All is stored in versions, the newest record is used as the value but you can get
whole history of value changes and you can work with it.</p></div>
<div class="ulist"><ul><li><p><a href="https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html" class="bare">https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html</a> (Please stop calling databases CP or AP, Martin Kleppmann)</p></li><li><p><a href="http://guide.couchdb.org/draft/consistency.html" class="bare">http://guide.couchdb.org/draft/consistency.html</a> (Eventual Consistency, CouchDB)</p></li><li><p><a href="https://www.youtube.com/watch?v=H0i_bXKwujQ" class="bare">https://www.youtube.com/watch?v=H0i_bXKwujQ</a> (Building Scalable Stateful Services, Caitie McCaffrey, GOTO 2015 [cp vs. ap])</p></li></ul></div></aside></section>
<section id="_calm_acid_2_0_crdt"><h2>CALM, ACID 2.0, CRDT</h2><div class="dlist"><dl><dt class="hdlist1"><strong>CALM</strong></dt><dd><p>consistency as logical monotonicity</p></dd><dt class="hdlist1"><strong>ACID 2.0</strong></dt><dd><p>associative, commutative, idempotent, distributed (whatever)</p></dd><dt class="hdlist1"><strong>CRDT</strong></dt><dd><p>conflict-free replicated data type</p></dd></dl></div>
<aside class="notes"><div class="paragraph"><p>Eventual consistency with strong guarantees : CALM, ACID 2.0, CRDT</p></div>
<div class="paragraph"><p>CALM</p></div>
<div class="paragraph"><p>Moving responsibility to define where coordination is needed to creator of program.
It provides tooling to define what are the "weak points" of the program and where
coordination will be needed. Other parts are fine to be left as "AP" without any
coordination enforced.</p></div>
<div class="paragraph"><p>Accordingly, CALM tells programmers which operations and programs can guarantee safety
when used in an eventually consistent system. Any code that fails CALM tests is a candidate
for stronger coordination mechanisms.</p></div>
<div class="paragraph"><p>A Bloom program may be viewed as a dataflow graph with external input interfaces as sources,
external output interfaces as sinks, collections as internal nodes, and rules as edges.
This graph represents the dependencies between the collections in a program and
is generated automatically by the Bud interpreter.</p></div>
<div class="paragraph"><p>What the documentation on Bloom language says</p></div>
<div class="listingblock"><div class="content"><pre class="highlight"><code>One of the key innovations underlying Bloom is the ability to formally guarantee consistency
properties of distributed programs.  This reasoning is based on the CALM principle,
which was the subject of recent theoretical results.  This theory applies to any programming paradigm,
but Bloom’s roots in logic make it easy for us to convert the theory into practical tools for Bloom programmers.</code></pre></div></div>
<div class="paragraph"><p>In some simplistic way we can say that CALM says that the system can grow only in one
direction. As counter that can only increase its value and no going down.</p></div>
<div class="paragraph"><p>I-confluence by Peter Bailis, by his words</p></div>
<div class="listingblock"><div class="content"><pre class="highlight"><code>CALM says that, if your program logic is monotonic http://bloom-lang.net/calm/,
your program outputs will be deterministic, or confluent, despite re-ordering.

In this work, we say that, if your program logic is I-confluent with respect to some arbitrary,
user-specified invariant, you can preserve that invariant without coordination.</code></pre></div></div>
<div class="paragraph"><p>ACID 2.0</p></div>
<div class="paragraph"><p>Reusing ACID for distributed systems.</p></div>
<div class="paragraph"><p>When all operation in distributed systems bind the properties of ACID 2.0 then
we get the CRDT. I understand it as CRDT is "the implementation" of the ACID 2.0
definition.</p></div>
<div class="paragraph"><p>Example as everytime is balance of an account. We can say starting balance 50, then
decrease for 10 and later increase for 20, we have 60.</p></div>
<div class="paragraph"><p>The acid 2.0 is about no mutability permitted. We rather saying starting balance at time and then
events saying decreasing by 10 at some timestamp, this info is saved (in some log?)
the same for increase. By combination of the idempotentcy and rules of commutativity
and associativity we don&#8217;t care about order that the records are received by nodes.</p></div>
<div class="paragraph"><p>CRDT</p></div>
<div class="ulist"><ul><li><p>a type of specially-designed data structure used to achieve strong eventual consistency</p></li><li><p>basically they are datastructures that could be used with set of operation which
are capable to resolve conflict. The basic example is a counter - it&#8217;s implemented
in way of not setting a state but list of additions. When split brain occurs then
each partion is free to add addition (+1) to list of addition. When the cluster is joint
again there is a function which defines how to resolve the conflict (e.g. part one
  receives request for +1 and part two three request for +1). The function just takes
  additions and sum that up. The resolution for the conflict is +4.</p></li><li><p>Two types</p><div class="ulist"><ul><li><p>Operation-based CRDTs</p></li><li><p>State-based CRDTs</p></li></ul></div></li><li><p><a href="http://www.se-radio.net/2016/03/se-radio-episode-252-christopher-meiklejohn-on-crdts" class="bare">http://www.se-radio.net/2016/03/se-radio-episode-252-christopher-meiklejohn-on-crdts</a></p></li><li><p><a href="https://medium.com/@istanbul_techie/a-look-at-conflict-free-replicated-data-types-crdt-221a5f629e7e" class="bare">https://medium.com/@istanbul_techie/a-look-at-conflict-free-replicated-data-types-crdt-221a5f629e7e</a></p></li><li><p><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type" class="bare">https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type</a></p></li><li><p><a href="https://blog.acolyer.org/2015/03/16/consistency-analysis-in-bloom-a-calm-and-collected-approach" class="bare">https://blog.acolyer.org/2015/03/16/consistency-analysis-in-bloom-a-calm-and-collected-approach</a></p></li><li><p><a href="http://bloom-lang.net/calm/" class="bare">http://bloom-lang.net/calm/</a></p></li><li><p><a href="http://www.bailis.org/blog/when-does-consistency-require-coordination" class="bare">http://www.bailis.org/blog/when-does-consistency-require-coordination</a></p></li><li><p><a href="http://queue.acm.org/detail.cfm?id=2462076" class="bare">http://queue.acm.org/detail.cfm?id=2462076</a></p></li><li><p><a href="https://blog.acolyer.org/2015/03/16/consistency-analysis-in-bloom-a-calm-and-collected-approach" class="bare">https://blog.acolyer.org/2015/03/16/consistency-analysis-in-bloom-a-calm-and-collected-approach</a></p></li><li><p><a href="https://blog.acolyer.org/2015/09/08/out-of-the-fire-swamp-part-i-the-data-crisis" class="bare">https://blog.acolyer.org/2015/09/08/out-of-the-fire-swamp-part-i-the-data-crisis</a></p></li><li><p><a href="https://blog.acolyer.org/2015/09/09/out-of-the-fire-swamp-part-ii-peering-into-the-mist" class="bare">https://blog.acolyer.org/2015/09/09/out-of-the-fire-swamp-part-ii-peering-into-the-mist</a></p></li><li><p><a href="https://blog.acolyer.org/2015/09/10/out-of-the-fire-swamp-part-iii-go-with-the-flow" class="bare">https://blog.acolyer.org/2015/09/10/out-of-the-fire-swamp-part-iii-go-with-the-flow</a></p></li><li><p><a href="https://www.youtube.com/watch?v=em9zLzM8O7c" class="bare">https://www.youtube.com/watch?v=em9zLzM8O7c</a> ("Consistency without consensus in production systems" by Peter Bourgon)</p></li><li><p><a href="https://lostechies.com/jimmybogard/2013/06/06/acid-2-0-in-action" class="bare">https://lostechies.com/jimmybogard/2013/06/06/acid-2-0-in-action</a></p></li><li><p><a href="http://www.enterpriseintegrationpatterns.com/ramblings/68_acid.html" class="bare">http://www.enterpriseintegrationpatterns.com/ramblings/68_acid.html</a></p></li><li><p><a href="https://medium.com/@istanbul_techie/a-look-at-conflict-free-replicated-data-types-crdt-221a5f629e7e" class="bare">https://medium.com/@istanbul_techie/a-look-at-conflict-free-replicated-data-types-crdt-221a5f629e7e</a></p></li></ul></div></aside></section>
<section id="_sql_vs_nosql_vs_newsql"><h2>SQL vs. NoSQL vs. NewSQL</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/nosql-sql-comparision.jpg" alt="nosql sql comparision"></span></p></div>
<div class="ulist"><ul><li><p><em>source:</em> <a href="https://blogs.the451group.com/information_management/2011/04/15/nosql-newsql-and-beyond">https://blogs.the451group.com</a></p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Difference in terms of SQL, NoSQL and NewSQL is fuzzy. There is difference if SQL
is used. But here in terms is rather kind of:</p></div>
<div class="ulist"><ul><li><p><strong>SQL</strong> == <strong>AC</strong> (RBMS)</p></li><li><p><strong>NoSQL</strong> == <strong>AP</strong></p></li><li><p><strong>NewSQL</strong> == <strong>CP</strong></p></li></ul></div>
<div class="paragraph"><p>NewSQL examples NuoDB, VoltDB. Plus we can talk about systems like IBM HANA or
possibly Google Spanner (when focused on strong consistency).
And then probably even DynamoDB and CrockroachDB which added some
stronger transaction abilities.</p></div>
<div class="ulist"><ul><li><p><a href="https://blogs.the451group.com/information_management/2011/04/15/nosql-newsql-and-beyond" class="bare">https://blogs.the451group.com/information_management/2011/04/15/nosql-newsql-and-beyond</a></p></li><li><p><a href="http://dataconomy.com/2015/08/sql-vs-nosql-vs-newsql-finding-the-right-solution" class="bare">http://dataconomy.com/2015/08/sql-vs-nosql-vs-newsql-finding-the-right-solution</a></p></li><li><p><a href="https://aphyr.com/posts/331-jepsen-voltdb-6-3" class="bare">https://aphyr.com/posts/331-jepsen-voltdb-6-3</a></p></li><li><p><a href="https://www.nuodb.com/product/durable-distributed-cache" class="bare">https://www.nuodb.com/product/durable-distributed-cache</a></p></li><li><p><a href="http://www.methodsandtools.com/archive/acidnosql.html" class="bare">http://www.methodsandtools.com/archive/acidnosql.html</a></p></li></ul></div></aside></section>
<section id="_2pc"><h2>2PC</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/2pc.png" alt="2pc"></span></p></div>
<aside class="notes"><div class="ulist"><ul><li><p>CA (consistency + availability). Examples include full strict quorum protocols,
such as two-phase commit.</p></li></ul></div>
<div class="paragraph"><p>2PC: atomic commitment protocol (ACP), a specialized type of consensus protocol</p></div>
<div class="paragraph"><p>Why not 2PC (<a href="http://stackoverflow.com/questions/37297766/best-practices-of-distributed-transactionsjava" class="bare">http://stackoverflow.com/questions/37297766/best-practices-of-distributed-transactionsjava</a>)</p></div>
<div class="ulist"><ul><li><p>Some problems of 2PC comes from the fact that the coordinator is a single point of failure. If it is down then
the system is unavailable, if there is a network partitioning and the coordinator happens to be in other partition
than clients and resources then the system is also unavailable.</p></li><li><p>Another problem of the algorithm is its <strong>blocking nature</strong>: once a resource has sent an agreement message to the coordinator,
it will block until a commit or rollback is received. As a result the system can&#8217;t use all the potential of the hardware it uses.</p></li><li><p>it&#8217;s blocking - it does not progress during the failure</p></li></ul></div>
<div class="paragraph"><p>In context of consesus: <strong>2PC is safe but not live</strong></p></div>
<div class="paragraph"><p>For 2PC can&#8217;t be reach a safe decision when someone crashes/time-outs. Having only one participant
down it means no-one can proceed.</p></div>
<div class="ulist"><ul><li><p>2PC originated in year 1979 (Gray)</p></li><li><p>3PC in year 1981 (Stonebraker)</p></li><li><p>Paxos in year 1998 (Lamport)</p></li><li><p><a href="http://the-paper-trail.org/blog/consensus-protocols-two-phase-commit" class="bare">http://the-paper-trail.org/blog/consensus-protocols-two-phase-commit</a></p></li><li><p><a href="http://highscalability.com/blog/2013/5/1/myth-eric-brewer-on-why-banks-are-base-not-acid-availability.html" class="bare">http://highscalability.com/blog/2013/5/1/myth-eric-brewer-on-why-banks-are-base-not-acid-availability.html</a>
*</p></li></ul></div></aside></section>
<section id="_3pc"><h2>3PC</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/3pc.png" alt="3pc"></span></p></div>
<aside class="notes"><div class="paragraph"><p>As it was known about 2PC that&#8217;s safe but not live. Goal was creating consensus protocol
to be live (never block on node failures).</p></div>
<div class="paragraph"><p>3PC is live but it is not safe. 3PC has issue with network partitions where
data correctness is not assured.</p></div>
<div class="paragraph"><p>The protocol expects that node can&#8217;t be just unreachable but living. When it stop
to respond it&#8217;s expected to be dead.</p></div>
<div class="paragraph"><p>3PC splits commit/abort to two phases.
* let to know to all participants what was the outcome
* when all participants knows the outcome then commit (only that time)</p></div>
<div class="paragraph"><p>The base difference to 2PC is that in case of failure of participant or TM
protocol defines further execution for the system. When TM is not available
then after timeout participants can continue to work depending the phase they are in.
After the TM or participant is back, recovery process restore the system.</p></div>
<div class="ulist"><ul><li><p>if one of the participants receives <strong>preCommit</strong>, they all can <strong>commit</strong></p></li><li><p>if none received <strong>preCommit</strong>, they all can <strong>abort</strong></p></li><li><p><a href="https://roxanageambasu.github.io/ds-class//assets/lectures/lecture16.pdf" class="bare">https://roxanageambasu.github.io/ds-class//assets/lectures/lecture16.pdf</a></p></li><li><p><a href="http://planet.jboss.org/post/2pc_or_3pc" class="bare">http://planet.jboss.org/post/2pc_or_3pc</a></p></li><li><p><a href="http://the-paper-trail.org/blog/consensus-protocols-three-phase-commit" class="bare">http://the-paper-trail.org/blog/consensus-protocols-three-phase-commit</a></p></li><li><p><a href="https://cseweb.ucsd.edu/classes/wi17/cse291-d/applications/ln/lecture8.html" class="bare">https://cseweb.ucsd.edu/classes/wi17/cse291-d/applications/ln/lecture8.html</a></p></li></ul></div></aside></section>
<section id="_distributed_commitment"><h2>Distributed commitment</h2><div class="ulist"><ul><li><p>2PC</p></li><li><p>3PC</p></li><li><p>Paxos</p></li></ul></div>
<aside class="notes"><div class="ulist"><ul><li><p><a href="http://the-paper-trail.org/blog/consensus-protocols-two-phase-commit" class="bare">http://the-paper-trail.org/blog/consensus-protocols-two-phase-commit</a></p></li><li><p><a href="https://www.quora.com/Distributed-Systems-What-is-a-simple-explanation-of-the-Paxos-algorithm" class="bare">https://www.quora.com/Distributed-Systems-What-is-a-simple-explanation-of-the-Paxos-algorithm</a></p></li><li><p><a href="http://dl.acm.org/citation.cfm?id=1132867" class="bare">http://dl.acm.org/citation.cfm?id=1132867</a></p></li></ul></div></aside></section>
<section id="__em_distributed_em_transactions"><h2><em>Distributed</em> transactions</h2><div class="ulist"><ul><li><p>Percolator&#8217;s transactions</p></li><li><p>RAMP transactions</p></li><li><p>(Google Spanner)</p></li><li><p>Compensating (SAGA) transactions</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>For Perclator and RAMP (and Spanner) We talk about transactions which is capable to work multiple records and provide
atomic commit with them.
For BASE we talk about eventual consistency where atomic commit is relaxed whole-over.</p></div>
<div class="ulist"><ul><li><p>If you want Serializable Isolation level then you should take a look on the <a href="http://research.google.com/pubs/pub36726.html">Percolator&#8217;s transactions</a>.
The Percolator&#8217;s transactions are quite known in the industry and have been used in the <a href="https://aws.amazon.com/blogs/aws/dynamodb-transaction-library/">Amazon&#8217;s DynamoDB transaction library</a>, in the <a href="https://www.cockroachlabs.com/blog/how-cockroachdb-distributes-atomic-transactions/">CockroachDB database</a>
and in the Google&#8217;s Pecolator system itself. <a href="http://rystsov.info/2016/03/02/cross-shard-txs.html">A step-by-step visualization</a> of the Percolator&#8217;s transactions may help you to understand it.</p></li><li><p>If you expect contention and can deal with Read Committed isolation level then <a href="http://www.bailis.org/papers/ramp-sigmod2014.pdf">RAMP transactions by Peter Bailis</a> may suit you.
I also created <a href="http://rystsov.info/2016/04/07/ramp.html">a step-by-step RAMP visualization</a>.</p></li><li><p>The third approach is to use compensating transactions also known as the saga pattern. It was described in the late 80s in the <a href="http://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf">Sagas paper</a>
but became more actual with the raise of distributed systems.</p></li></ul></div>
<div class="paragraph"><p><em>source StackOverflow</em>: <a href="http://stackoverflow.com/questions/36357429/how-to-manage-transactions-over-multiple-databases/36710510">how-to-manage-transactions-over-multiple-databases</a></p></div>
<div class="paragraph"><p><strong>HAT</strong> for Highly Available Transactions
* the paper comes with isolation/consistency analysis and introduces RAMP transactions</p></div>
<div class="paragraph"><p><strong>Google Spanner</strong>
* It is a distributed relational database that can distribute and store data in Google&#8217;s BigTable storage
  system in multiple data centers. Spanner meets ACID (of course, it supports transaction) and supports SQL.
  Currently, F1, Google&#8217;s advertisement platform, uses Spanner. Gmail and Google Search will also use it soon.
* Spanner is interesting by usage <strong>TrueTime API</strong>: TrueTime gets time information from GPS and the atomic clock</p></div>
<div class="paragraph"><p><strong>SAGA</strong>
* trade-off: <code>atomicity</code> for <code>availability</code> (stated by Caitie in his GOTO 2015 presentation)
* I personally do not totally agree with it, I like the point of view of Martin Kleppmann
  from his presentation at Strange Loop 2015 where he defines <code>atomicity</code> as <code>abortability</code>. That&#8217;s what Saga
  is designed for - being able to compensate a.k.a abort the unit of work as a whole.
  Saga then has rather trade-off of <code>isolation</code> for <code>availability</code>.</p></div>
<div class="paragraph"><p><strong>RAMP</strong>
* based on paper from Peter Bailis and others (UC Berkeley and University of Sydney)
* does not provide ACID guarantees but the goal is to achieve atomic reads of multiple items
* each partition maintains version history for items, it&#8217;s consisted from tuple like <code>(item, value, timestamp, metadata)</code>
* RAMP uses 2 phase commit but without exclusive locking
* three versions of the protocol like <code>RAMP-Fast</code>, <code>RAMP-Small</code>, <code>RAMP-Hybrid</code>
<strong> metadata contains 'dependency' - in this context it means what other items are part of the atomic update,
   for example we want update item 'X' and 'Y'. Item 'X' is set to value '1' and 'Y' to '2'. When we read 'Y'
   DB returns value with timestamp and dependency. We can now compare if getting 'X' and 'Y' has the same timestamp
   which is important if 'X' and 'Y' was part of the same transaction - which we found out by checking metadata dependency information.
</strong> if there is a discrepancy we ask for the value with the smaller timestamp again to get updated value
* you really need to read a nice concise summary from Jon Haddad - RAMP Made easy</p></div>
<div class="ulist"><ul><li><p><a href="http://www.bailis.org/blog/hat-not-cap-introducing-highly-available-transactions" class="bare">http://www.bailis.org/blog/hat-not-cap-introducing-highly-available-transactions</a></p></li><li><p><a href="https://www.linkedin.com/pulse/client-side-transactions-distributed-data-stores-denis-rystsov" class="bare">https://www.linkedin.com/pulse/client-side-transactions-distributed-data-stores-denis-rystsov</a></p></li><li><p><a href="https://www.youtube.com/watch?v=53DVkaW5Fb0" class="bare">https://www.youtube.com/watch?v=53DVkaW5Fb0</a></p></li><li><p><a href="https://www.youtube.com/watch?v=xDuwrtwYHu8" class="bare">https://www.youtube.com/watch?v=xDuwrtwYHu8</a> (GOTO 2015, Applying the Saga Pattern, Caitie McCaffrey)</p></li><li><p><a href="https://www.youtube.com/watch?v=5ZjhNTM8XU8" class="bare">https://www.youtube.com/watch?v=5ZjhNTM8XU8</a> ("Transactions: myths, surprises and opportunities" by Martin Kleppmann)</p></li><li><p><a href="https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf" class="bare">https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf</a> (Princeton University, 1987)</p></li><li><p><a href="http://www.bailis.org/blog/scalable-atomic-visibility-with-ramp-transactions" class="bare">http://www.bailis.org/blog/scalable-atomic-visibility-with-ramp-transactions</a></p></li><li><p><a href="https://dzone.com/articles/spanner-globally-distributed" class="bare">https://dzone.com/articles/spanner-globally-distributed</a></p></li><li><p><a href="http://rustyrazorblade.com/2015/11/ramp-made-easy" class="bare">http://rustyrazorblade.com/2015/11/ramp-made-easy</a> (Jon Haddad, RAMP Made easy)</p></li><li><p><a href="http://rustyrazorblade.com/2015/11/ramp-made-easy-part-2" class="bare">http://rustyrazorblade.com/2015/11/ramp-made-easy-part-2</a></p></li><li><p><a href="https://www.infoq.com/presentations/spanner-distributed-google" class="bare">https://www.infoq.com/presentations/spanner-distributed-google</a></p></li></ul></div></aside></section>
<section id="_definition_base"><h2>Definition BASE</h2><div class="ulist"><ul><li><p><strong>BA</strong> for basic availability</p></li><li><p><strong>S</strong> for soft-state</p></li><li><p><strong>E</strong> for eventual consistency</p></li></ul></div>
<aside class="notes"><div class="ulist"><ul><li><p><strong>Basic Availability</strong> - The database appears to work most of the time.</p></li><li><p><strong>Soft-state</strong> - Stores don’t have to be write-consistent, nor do different replicas have to be mutually consistent all the time.</p></li><li><p><strong>Eventual consistency</strong> - Stores exhibit consistency at some later point (e.g., lazily at read time).</p></li></ul></div>
<div class="paragraph"><p>BASE properties are much looser than ACID guarantees, but there isn’t a direct one-for-one mapping between the two consistency models.</p></div>
<div class="paragraph"><p>We can say that BASE transaction is used in NoSQL databases.
As we can say that ACID transaction is used in SQL databases.
We can say that ACID transaction is used in NewSQL databases.</p></div>
<div class="paragraph"><p><em>&#8230;&#8203;nothing particularly correct in these saying but it&#8217;s fine as simplification</em></p></div>
<div class="paragraph"><p>BASE is a way how to get a distributed transaction (transaction over multiple resources/databases) being available.</p></div>
<div class="ulist"><ul><li><p>Technique known as 2PC (two-phase commit) for providing ACID guarantees across multiple database instances.</p></li><li><p>ACID provides the consistency choice for partitioned databases, then how do you achieve availability instead? One answer is BASE.</p></li><li><p><a href="https://neo4j.com/blog/acid-vs-base-consistency-models-explained" class="bare">https://neo4j.com/blog/acid-vs-base-consistency-models-explained</a></p></li><li><p><a href="https://neo4j.com/blog/aggregate-stores-tour" class="bare">https://neo4j.com/blog/aggregate-stores-tour</a></p></li><li><p><a href="http://queue.acm.org/detail.cfm?id=1394128" class="bare">http://queue.acm.org/detail.cfm?id=1394128</a> (Base: An Acid Alternative, base transactions)</p></li><li><p><a href="http://highscalability.com/blog/2013/5/1/myth-eric-brewer-on-why-banks-are-base-not-acid-availability.html" class="bare">http://highscalability.com/blog/2013/5/1/myth-eric-brewer-on-why-banks-are-base-not-acid-availability.html</a></p></li></ul></div></aside></section>
<section id="_msa_and_consistency"><h2>MSA and consistency</h2><div class="paragraph"><p><span class="image noborder"><img src="./misc/cap/eventdriven.png" alt="eventdriven"></span></p></div>
<div class="paragraph"><p><em>source:</em> <a href="http://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data">The Hardest Part About Microservices: Your Data</a></p></div>
<aside class="notes"><div class="paragraph"><p>In adopting the CQRS pattern for use in your application development, consider this transactional aspect of CQRS.
Commands cannot be lost. You need a transaction manager (to handle ACID transactions) to ensure that every command
is processed and that the events are generated and made persistent in the event store. This holds true for command handling,
but if you consider the entire transaction (from running the command to the event listener execution) in regard to the asynchronous
characteristics of flow, it is a BASE transaction.</p></div>
<div class="paragraph"><p><strong>Event Sourcing</strong> (ES) and <strong>Command Query Responsibility Segregation</strong> (CQRS) or <strong>Turning the Database Upside Down</strong></p></div>
<div class="paragraph"><p>from <a href="https://www.ibm.com/developerworks/cloud/library/cl-build-app-using-microservices-and-cqrs-trs" class="bare">https://www.ibm.com/developerworks/cloud/library/cl-build-app-using-microservices-and-cqrs-trs</a></p></div>
<div class="paragraph"><p>Implementation of CQRS saga base transaction is done in Axon Framework: <a href="http://www.axonframework.org" class="bare">http://www.axonframework.org</a></p></div>
<div class="paragraph"><p>A normalized database (with no redundancy) is optimized for writing, whereas a denormalized database is optimized for reading.</p></div>
<div class="paragraph"><p>&#8230;&#8203;change data capture (CDC) means using an existing database in the familiar way, but extracting any inserts, updates and
deletes into a stream of data change events which other applications can consume,
see <code>Debezium</code>.</p></div>
<div class="ulist"><ul><li><p><a href="http://www.grahamlea.com/2016/08/distributed-transactions-microservices-icebergs" class="bare">http://www.grahamlea.com/2016/08/distributed-transactions-microservices-icebergs</a> : Why distributed transactions are bad in MSA</p></li><li><p><a href="http://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data" class="bare">http://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data</a> : Data management in MSA, Ch. Posta</p></li><li><p><a href="http://debezium.io" class="bare">http://debezium.io</a> : Red Hat to event sourcing for DBs</p></li><li><p><a href="https://kafemlejnek.tv/dil-6-nastupujici-architektury-web-aplikaci" class="bare">https://kafemlejnek.tv/dil-6-nastupujici-architektury-web-aplikaci</a> : Kafemlejnek.tv</p></li><li><p><a href="http://programio.havrlant.cz/kafka" class="bare">http://programio.havrlant.cz/kafka</a> : Lukáš Havrlant blog</p></li><li><p><a href="https://github.com/cer/event-sourcing-examples" class="bare">https://github.com/cer/event-sourcing-examples</a> : examples of <a href="http://eventuate.io" class="bare">http://eventuate.io</a></p></li><li><p><a href="https://www.infoq.com/articles/microservices-aggregates-events-cqrs-part-1-richardson" class="bare">https://www.infoq.com/articles/microservices-aggregates-events-cqrs-part-1-richardson</a> : Developing Transactional Microservices Using Aggregates, Event Sourcing and CQRS - Part 1</p></li><li><p><a href="https://mapr.com/blog/how-stream-first-architecture-patterns-are-revolutionizing-healthcare-platforms" class="bare">https://mapr.com/blog/how-stream-first-architecture-patterns-are-revolutionizing-healthcare-platforms</a></p></li><li><p><a href="https://dzone.com/articles/microservices-with-spring-boot-axon-cqrses-anddock" class="bare">https://dzone.com/articles/microservices-with-spring-boot-axon-cqrses-anddock</a></p></li><li><p><a href="https://www.confluent.io/blog/making-sense-of-stream-processing" class="bare">https://www.confluent.io/blog/making-sense-of-stream-processing</a></p></li><li><p><a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying" class="bare">https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying</a></p></li></ul></div></aside></section>
<section><div class="paragraph"><p><span class="image noborder"><img src="./misc/entertain/cajk.jpg" alt="cajk" height="300"></span></p></div>
<div class="ulist"><ul><li><p><a href="http://book.mixu.net/distsys">Distributed systems: for fun and profit</a></p></li><li><p><a href="http://dataintensive.net">Design Data-intensive Applications</a></p></li><li><p><a href="http://the-paper-trail.org/blog/distributed-systems-theory-for-the-distributed-systems-engineer">Distributed systems theory for the distributed systems engineer</a></p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Info dump from several sources, mixed, just for inspiration.</p></div>
<div class="paragraph"><p>Scaling - vertical and horizontal</p></div>
<div class="ulist"><ul><li><p>Vertical scaling often creates vendor lock, further adding to costs.</p></li><li><p>Horizontal scaling offers more flexibility but is also considerably more complex.</p></li></ul></div>
<div class="paragraph"><p>Partitioning - Partitioning is dividing the dataset into smaller distinct independent sets</p></div>
<div class="ulist"><ul><li><p>Replication improves performance by making additional computing power and bandwidth applicable to a new copy of the data</p></li><li><p>Replication improves availability by creating additional copies of the data, increasing the number of nodes that need to fail before availability is sacrificed</p></li></ul></div>
<div class="paragraph"><p>Replication - Replication is making copies of the same data on multiple machines</p></div>
<div class="ulist"><ul><li><p>Replication improves performance by making additional computing power and bandwidth applicable to a new copy of the data</p></li><li><p>Replication improves availability by creating additional copies of the data, increasing the number of nodes that need to fail before availability is sacrificed</p></li></ul></div>
<div class="paragraph"><p>Any horizontal scaling strategy is based on data partitioning; therefore,
designers are forced to decide between consistency and availability.</p></div></aside></section></div></div><script src="reveal.js/lib/js/head.min.js"></script><script src="reveal.js/js/reveal.js"></script><script>// See https://github.com/hakimel/reveal.js#configuration for a full list of configuration options
Reveal.initialize({
  // Display controls in the bottom right corner
  controls: false,
  // Display a presentation progress bar
  progress: true,
  // Display the page number of the current slide
  slideNumber: false,
  // Push each slide change to the browser history
  history: false,
  // Enable keyboard shortcuts for navigation
  keyboard: true,
  // Enable the slide overview mode
  overview: true,
  // Vertical centering of slides
  center: true,
  // Enables touch navigation on devices with touch input
  touch: true,
  // Loop the presentation
  loop: false,
  // Change the presentation direction to be RTL
  rtl: false,
  // Turns fragments on and off globally
  fragments: true,
  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,
  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,
  // Stop auto-sliding after user input
  autoSlideStoppable: true,
  // Enable slide navigation via mouse wheel
  mouseWheel: false,
  // Hides the address bar on mobile devices
  hideAddressBar: true,
  // Opens links in an iframe preview overlay
  previewLinks: false,
  // Theme (e.g., beige, black, league, night, serif, simple, sky, solarized, white)
  // NOTE setting the theme in the config no longer works in reveal.js 3.x
  //theme: Reveal.getQueryHash().theme || 'redhat',
  // Transition style (e.g., none, fade, slide, convex, concave, zoom)
  transition: Reveal.getQueryHash().transition || 'fade',
  // Transition speed (e.g., default, fast, slow)
  transitionSpeed: 'default',
  // Transition style for full page slide backgrounds (e.g., none, fade, slide, convex, concave, zoom)
  backgroundTransition: 'fade',
  // Number of slides away from the current that are visible
  viewDistance: 3,
  // Parallax background image (e.g., "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'")
  parallaxBackgroundImage: '',
  // Parallax background size in CSS syntax (e.g., "2100px 900px")
  parallaxBackgroundSize: '',

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 960,
  height: 700,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.5,

  // Optional libraries used to extend on reveal.js
  dependencies: [
      { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      
      { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
      { src: 'reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
  ]
});</script></body></html>